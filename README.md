# Conversational AI Agent â€“ Project 

### Smart TV OS â€“ AI Voice-to-Action System

---

## âœ… 1. Feature Overview

The Conversational AI Agent is an end-to-end **Voice-to-Action** application integrated into the Smart TV OS. The user speaks naturally, the system understands the command, retrieves information if needed, executes the action on the TV, and responds using voice + UI.

### Core Capabilities

- Natural voice commands (hands-free control)
- Intelligent search (movies, actors, news, etc.)
- Launch and interact with apps
- Control system settings (volume, subtitles, brightness)
- Provide information and summaries when requested

### Why It Matters

- Creates a **smarter, more intuitive TV experience**
- Accessible for users with disabilities
- Faster navigation than remote controls
- A key innovation in the Smart TV OS project

---

## âœ… 2. How It Works (Pipeline)

```
Voice Input â†’ ASR â†’ NLU + Dialog Manager â†’ Action Planner â†’ App/System Control
                                     â†“
                                    RAG (optional, for knowledge queries)
                                     â†“
                                   TTS Reply + UI
```

| Stage      | Component          | Purpose                                       |
| ---------- | ------------------ | --------------------------------------------- |
| 1          | STT/ASR            | Convert speech to text                        |
| 2          | Intent Recognition | Understand what the user wants                |
| 3          | Entity Extraction  | Detect titles, actors, etc.                   |
| 4          | Action Execution   | Search, play, launch apps, adjust settings    |
| 5          | RAG                | Fetch fresh information (e.g., news, ratings) |
| 6          | TTS                | Convert text to speech back to the user       |

---

## âœ… 4. Implementation Plan

### ðŸ“Œ Phase 1 â€” Core Voice System (Weeks 1â€“4)

- **STT Integration:** Add Whisper ASR (local or API)
- **NLU/LLM:** Build NLU + **Intent classification model** for Play / Search / Settings
- **Data Collection & Annotation:** Gather training phrases from real usage for fineâ€‘tuning
- TTS: Build a basic TTS response system
- **Action Planner Module:** Maps predicted intent â†’ OS actions
- **System Control API Integration:** Connect Action Planner to TV OS services for execution,Â Integrate Speech-to-TextÂ 

**Deliverable:** First demo of basic commands

---

### ðŸ“Œ Phase 2 â€” App Integration & UI Responses & RAG (Weeks 5â€“8)

- Connect with YouTube (deep-link queries)
- Launch browser with results
- Control system settingsÂ 
- RAG: Retriever system and Vector DB for basic Q&A
- Display search results visually with selection
- Dialog Manager for yes/no confirmations

**Deliverable:** Full navigation + visible response demo

---

### ðŸ“Œ Phase 3 â€” Intelligence Enhancements (Weeks 9â€“12)

- Optional: Cloud LLM for complex Q&A(performance, cost)
- Reduce Speech Noise in home environment
- Enhance RAG for complex Q&A
- Multi-user personalization & memory
- UX polish + latency improvements

**Deliverable:** Final polished demo for jury

---

## âœ… 5. Technologies & Tools

> **Strategy**: Prefer openâ€‘source models first (fineâ€‘tuning if required). Use closedâ€‘source/cloud only if performance is insufficient.

- **ASR (STT):** Openâ€‘source Whisper (local or API) / alternative Hugging Face(HF) models
- **NLU / LLM:** Openâ€‘source Llama/Mistral models + Intent Classifier (Preferred Arabic Models)
- **Action Planner:** OS Control Service (custom)
- **TTS:** Openâ€‘source HF TTS (e.g., VITS) then fallback to cloud TTS if needed
- **RAG (Future Upgrade):** FAISS vector DB + app/public API connectors
- **Programming Languages:** Python + OS SDK

---

## âœ… 5.1 System Architecture Diagram (High-Level)

```
ðŸŽ¤ Voice Input
        â†“
[ ASR (Whisper) ] â€” Converts speech â†’ text
        â†“
[ NLU / LLM (Llama/Mistral) ] â€” Understands intent + entities
        â†“
[ Dialog & Action Planner ] â€” Decides what to do
        â†“
[ TV OS Control Service ] â€” Executes actions on system/apps
        â†“
ðŸ“º UI Feedback + ðŸ”Š TTS Response
```

Cloud / Local Strategy:

- **Local GPU (preferred):** ASR, Intent Handling, Basic NLU
- **Cloud API (optional):** Complex reasoning, fallback TTS

A hybrid approach ensures **low latency** + **wide functionality**.

---

## âœ… 5.2 Model Candidates (Open Source First)

| Component         | Model Options                      | Source         | Notes                           |
| ----------------- | ---------------------------------- | -------------- | ------------------------------- |
| STT               | Whisper Small / Medium             | Open-source HF | Good accuracy, local inference  |
| NLU / LLM         | Llama-3-8B, Mistral 7B, Qwen 2Bâ€“7B | HF             | Needs fine-tuning for intents   |
| Intent Classifier | DistilBERT / BERT Mini             | HF             | Lightweight on-device           |
| TTS               | VITS / FastSpeech2                 | HF             | Natural speech; GPU recommended |
| RAG Vector DB     | FAISS                              | Open-source    | Used later for advanced search  |

Fallback Cloud Options (if needed): OpenAI, Azure Cognitive Services, Google Speech APIs

---

## âœ… 6. Success Metrics

| Metric                  | Target            |
| ----------------------- | ----------------- |
| Intent accuracy         | â‰¥ 90%             |
| End-to-end success rate | â‰¥ 85%             |
| Response latency        | 1â€“3 sec           |
| Jury evaluation score   | 100% impressed ðŸ˜„ |

---

## âœ… 7. Demo Script (for presentation day)

Examples:

1. "Play the latest episode of Planet Earth" â†’ plays content
2. "Open YouTube and search football highlights" â†’ launches YouTube
3. "Turn subtitles on" â†’ subtitles enabled
4. "What are critics saying about the new Batman movie?" â†’ response summary
